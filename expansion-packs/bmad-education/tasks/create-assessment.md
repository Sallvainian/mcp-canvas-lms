# Create Assessment Task

## Purpose
Design valid, reliable, and fair assessments (formative and summative) that accurately measure learning objectives, provide actionable feedback, and support student growth while adhering to assessment design principles and best practices.

## Prerequisites
- Learning objectives clearly defined (see `create-learning-objectives.md`)
- Understanding of assessment types and purposes
- Familiarity with Bloom's Taxonomy and DOK levels
- Access to Canvas MCP tools
- Knowledge of your learner population

## Step-by-Step Process

### Step 1: Determine Assessment Purpose and Type

#### 1.1 Clarify Assessment Purpose
**Formative Assessment** (Assessment FOR Learning):
- **Purpose**: Monitor learning progress, provide feedback, adjust instruction
- **Stakes**: Low or no-stakes
- **Frequency**: Frequent, ongoing
- **Feedback**: Immediate, specific, actionable
- **Examples**: Exit tickets, quizzes, observations, discussions, self-assessments

**Summative Assessment** (Assessment OF Learning):
- **Purpose**: Evaluate mastery, assign grades, certify achievement
- **Stakes**: Moderate to high
- **Frequency**: End of unit/course
- **Feedback**: Evaluative, may be delayed
- **Examples**: Unit tests, final projects, standardized exams, portfolios

**Diagnostic Assessment** (Assessment to Start Learning):
- **Purpose**: Identify prior knowledge, prerequisite gaps, misconceptions
- **Stakes**: No-stakes
- **Frequency**: Beginning of unit/course
- **Examples**: Pre-tests, concept inventories, surveys

#### 1.2 Select Assessment Method
**Selected Response** (choose from options):
- Multiple choice, true/false, matching
- Efficient scoring, broad coverage
- Can assess higher-order thinking with careful design
- Limited ability to assess creation or complex performance

**Constructed Response** (create answer):
- Short answer, essay, explanation
- Assesses reasoning and communication
- Requires rubric for consistent scoring
- More time-consuming to grade

**Performance-Based** (demonstrate skill):
- Demonstrations, presentations, projects, portfolios
- Authentic, real-world application
- Assesses transfer and complex skills
- Requires detailed rubric and observation protocols

**Choice Criteria**:
- What does the objective require? (Knowledge? Skill? Understanding?)
- What cognitive level? (DOK 1-4, Bloom's level)
- What's practical given time, resources, class size?
- What provides most useful evidence of learning?

### Step 2: Align Assessment to Objectives

#### 2.1 Create Assessment Blueprint/Table of Specifications
1. **List All Learning Objectives**
   - What students should know and be able to do
   - Categorize by cognitive level (Bloom's/DOK)

2. **Determine Item Distribution**
   - How many items per objective?
   - Weight by importance/emphasis
   - Ensure all objectives assessed

3. **Create Blueprint Table**
```
Objective               | Bloom's | DOK | Items | Points | %
------------------------|---------|-----|-------|--------|----
Define food web terms   | Remember| 1   | 5 MC  | 5      | 10%
Explain energy flow     | Understand| 2 | 2 SA  | 10     | 20%
Analyze ecosystem case  | Analyze | 3   | 1 Essay| 25    | 50%
Evaluate conservation   | Evaluate| 3   | 1 Essay| 10    | 20%
------------------------|---------|-----|-------|--------|----
TOTAL                   |         |     | 9     | 50     | 100%
```

**Template**: `templates/assessment-blueprint.xlsx`

#### 2.2 Verify Cognitive Alignment
- **Objective DOK = Assessment DOK**
  - If objective requires analysis (DOK 3), assessment must require analysis (not just recall)
- **Bloom's level match**
  - "Explain" objective → explanation required in assessment
  - "Create" objective → creation/design task in assessment
- **Avoid Mismatch**
  - ❌ Objective: "Analyze data patterns" → Assessment: "List characteristics"
  - ✅ Objective: "Analyze data patterns" → Assessment: "Given this dataset, identify trends and explain causes"

### Step 3: Design Assessment Items

#### 3.1 Multiple Choice Items
**Best Practices**:
1. **Stem (question)**:
   - Clear, focused question or incomplete statement
   - Avoid unnecessary complexity
   - Can be phrased positively or negatively (mark negatives clearly)

2. **Options (choices)**:
   - One correct/best answer
   - 3-5 plausible distractors
   - Parallel structure
   - Similar length and complexity
   - Avoid "all of the above" and "none of the above"

3. **Assess Higher-Order Thinking**:
   - Present novel scenarios
   - Require application or analysis
   - Use data, graphs, passages to interpret

**Example - DOK 1 (Recall)**:
```
Which organisms are producers in a food web?
A. Plants
B. Herbivores
C. Carnivores
D. Decomposers
```

**Example - DOK 3 (Analysis)**:
```
A farmer notices that removing hawks from the farm
leads to crop damage from increased rodent populations.
Which ecological concept best explains this?

A. Biomagnification
B. Trophic cascade
C. Nutrient cycling
D. Primary succession

(Requires analyzing cause-effect relationships)
```

#### 3.2 Constructed Response Items
**Short Answer**:
- Specific, focused question
- Clear expectations for response
- Define expected length (words, sentences)
- Provide partial credit rubric

**Example**:
```
Explain in 2-3 sentences why removing a top predator
from an ecosystem often results in decreased plant growth.
Use the terms "trophic cascade" and "herbivores" in your answer.

Rubric:
3 pts: Accurate explanation with both required terms used correctly
2 pts: Mostly accurate explanation, minor errors
1 pt: Partially correct or missing key concepts
0 pts: Incorrect or no response
```

**Essay Questions**:
- Clear prompt with explicit task
- Specify format, length, required components
- Provide criteria for evaluation
- Use action verbs matching cognitive level
  - Analyze: "Compare and contrast...", "Examine the causes..."
  - Evaluate: "Justify your position...", "Critique the argument..."
  - Create: "Design a solution...", "Propose a plan..."

**Example**:
```
Prompt:
Analyze the ecological impact of introducing an invasive species
to a new ecosystem. Your essay should:
1. Describe the characteristics that make species invasive
2. Explain how invasive species disrupt food webs
3. Provide a real-world example with specific effects
4. Evaluate one proposed management strategy

Length: 500-750 words
Format: 5-paragraph essay with introduction, body, conclusion
```

#### 3.3 Performance Tasks
**Design Using GRASPS** (see `apply-backward-design.md`):
- **G**oal: What should students accomplish?
- **R**ole: What role will students assume?
- **A**udience: Who is the target audience?
- **S**ituation: What is the context/challenge?
- **P**roduct/Performance: What will students create?
- **S**tandards: Criteria for success (rubric)

**Example Performance Task**:
```
Goal: Design a sustainable ecosystem restoration plan
Role: Ecological consultant
Audience: Environmental organization board
Situation: A degraded wetland needs restoration with limited budget
Product:
  - Restoration plan document (5 pages)
  - Budget breakdown
  - 10-minute presentation with visual aids
Standards:
  - Ecological accuracy (species selection, food web balance)
  - Feasibility (budget, timeline, resources)
  - Communication (clarity, persuasiveness, professionalism)
  - Innovation (creative solutions to constraints)
```

**Rubric Required**: See `create-rubric.md` for detailed rubric design

### Step 4: Ensure Assessment Quality

#### 4.1 Validity (Does it measure what it claims to measure?)
**Content Validity**:
- All learning objectives represented?
- Appropriate emphasis/weighting?
- Items match cognitive level of objectives?
- No irrelevant or trick questions?

**Construct Validity**:
- Assesses intended construct (e.g., understanding, not just reading ability)
- Free from bias (cultural, linguistic, experiential)
- Clear, unambiguous items

**Validity Checks**:
- [ ] Assessment blueprint shows complete objective coverage
- [ ] Each item maps to specific objective
- [ ] Cognitive levels aligned (objective DOK = item DOK)
- [ ] No irrelevant difficulty (confusing wording, trick questions)
- [ ] Accessible to diverse learners (see `apply-udl.md`)

#### 4.2 Reliability (Consistent, dependable results?)
**Internal Consistency**:
- Items measure the same construct
- No contradictory items
- Adequate number of items per objective (3+ recommended)

**Scoring Consistency**:
- Clear rubrics for constructed response
- Inter-rater reliability (multiple scorers agree)
- Consistent application of criteria

**Reliability Enhancements**:
- Use rubrics with specific descriptors
- Train scorers (if multiple)
- Provide anchor papers/exemplars
- Minimize ambiguity in questions and scoring

#### 4.3 Fairness and Accessibility
**Fairness Principles**:
- Free from bias (cultural, linguistic, gender, etc.)
- Assesses learning, not background knowledge unrelated to objectives
- Multiple opportunities to demonstrate learning
- Reasonable accommodations available

**Accessibility Checks** (see `accessibility-audit.md`):
- [ ] Clear, readable text (font, size, contrast)
- [ ] Alternative formats available (large print, digital, audio)
- [ ] Assistive technology compatible
- [ ] Accommodations for disabilities (extended time, scribe, etc.)
- [ ] Language accessible (vocabulary, sentence structure)

**UDL in Assessment** (see `apply-udl.md`):
- Multiple means of expression (demonstrate learning in varied ways)
- Options for engagement (choice in topics, formats where appropriate)
- Clear expectations and models

### Step 5: Build Assessment in Canvas

#### 5.1 Create Canvas Assignment
```python
canvas_create_assignment(
    course_id=12345,
    name="Unit 3 Assessment: Ecosystem Dynamics",
    description="""
    <h3>Assessment Overview</h3>
    <p>This assessment measures your understanding of food webs,
    trophic cascades, and ecosystem interactions.</p>

    <h3>Learning Objectives Assessed</h3>
    <ul>
      <li>Explain energy flow in food webs (20%)</li>
      <li>Analyze ecosystem disruption scenarios (50%)</li>
      <li>Evaluate conservation strategies (30%)</li>
    </ul>

    <h3>Format</h3>
    <ul>
      <li>Part A: 10 multiple choice (20 points)</li>
      <li>Part B: 2 short answer (20 points)</li>
      <li>Part C: 1 essay (60 points)</li>
    </ul>

    <h3>Time</h3>
    <p>60 minutes in class, extended time available per IEP/504</p>

    <h3>Resources</h3>
    <p>One 3x5 notecard (handwritten) permitted. No other materials.</p>
    """,
    points_possible=100,
    grading_type="points",
    submission_types=["online_text_entry", "online_upload"],
    allowed_attempts=1,
    due_at="2025-10-15T14:30:00Z"
)
```

#### 5.2 Build Quiz in Canvas (for objective items)
```python
canvas_create_quiz(
    course_id=12345,
    title="Unit 3 Quiz: Food Web Fundamentals",
    description="[Quiz overview and instructions]",
    quiz_type="assignment",
    time_limit=30,  # minutes
    allowed_attempts=2,  # for formative
    show_correct_answers=True,  # after submission
    one_question_at_a_time=False,
    shuffle_answers=True
)

# Add questions
canvas_create_quiz_question(
    course_id=12345,
    quiz_id=67890,
    question_name="Q1: Producer Identification",
    question_text="Which organisms are producers?",
    question_type="multiple_choice",
    points_possible=2,
    answers=[
        {"text": "Plants", "weight": 100},  # correct
        {"text": "Herbivores", "weight": 0},
        {"text": "Carnivores", "weight": 0},
        {"text": "Decomposers", "weight": 0}
    ]
)
```

#### 5.3 Attach Rubric
```python
canvas_create_rubric(
    course_id=12345,
    title="Essay Question Rubric",
    criteria=[
        {
            "description": "Analysis of Ecosystem Impact",
            "points": 20,
            "ratings": [
                {"description": "Thorough, sophisticated analysis", "points": 20},
                {"description": "Clear analysis with minor gaps", "points": 15},
                {"description": "Basic analysis, some inaccuracies", "points": 10},
                {"description": "Minimal or incorrect analysis", "points": 5}
            ]
        },
        # Additional criteria...
    ],
    free_form_criterion_comments=True
)

# Associate rubric with assignment
# (Rubric ID linked to assignment in Canvas)
```

### Step 6: Prepare for Administration

#### 6.1 Create Assessment Materials
- **Student Version**: Questions, prompts, materials
- **Answer Key**: Correct answers with explanations
- **Rubric**: Scoring guide for constructed response
- **Accommodations**: Modified versions as needed

**Canvas Tools**:
- `canvas_create_page` for instructions and resources
- `canvas_list_files` to attach supplementary materials

#### 6.2 Write Clear Instructions
```
Assessment Instructions Template:

1. Purpose: What this assessment measures
2. Format: Types of questions and structure
3. Time: Duration and time management tips
4. Resources: What's allowed/prohibited
5. Submission: How and when to submit
6. Scoring: How work will be evaluated
7. Accommodations: How to access (if applicable)
8. Support: Where to get help if needed
```

#### 6.3 Plan Administration Logistics
- **Scheduling**: Date, time, location
- **Proctoring**: Supervision procedures
- **Technology**: Platform, tools, backups
- **Accommodations**: Extended time, separate setting, assistive tech
- **Make-up Policy**: Absences, late submissions

### Step 7: Administer and Collect Evidence

#### 7.1 Administer Assessment
- Provide clear instructions
- Monitor for questions and issues
- Maintain test security and academic integrity
- Ensure equitable conditions for all students

#### 7.2 Collect Submissions
**Canvas Tools**:
- `canvas_get_submission` to review individual work
- `canvas_list_submissions` to track completion
- Monitor submission times and late work

### Step 8: Score and Provide Feedback

#### 8.1 Score Consistently
**Selected Response**:
- Use answer key
- Canvas auto-scores objective items
- Review flagged or ambiguous responses

**Constructed Response**:
- Use rubric for all responses
- Score one question at a time (consistency)
- Blind scoring when possible (no names)
- Calibrate with colleague (inter-rater reliability)

**Canvas Tools**:
```python
# Submit grades
canvas_update_submission_grade(
    course_id=12345,
    assignment_id=67890,
    user_id=111,
    posted_grade=85,
    text_comment="Strong analysis in Part C. Review energy
                 flow concepts for Part A (see feedback)."
)
```

#### 8.2 Provide Meaningful Feedback
**Feedback Principles**:
- **Timely**: Return within 3-5 days (sooner for formative)
- **Specific**: Reference exact aspects of work
- **Actionable**: Tell how to improve
- **Balanced**: Strengths and areas for growth
- **Forward-looking**: Connect to future learning

**Feedback Examples**:
- ❌ "Good job!" (vague)
- ❌ "You got this wrong." (not actionable)
- ✅ "Your analysis of the trophic cascade was accurate and detailed. To strengthen, add more specific evidence from the case study (see paragraph 3)."

**Canvas Feedback Tools**:
- Text comments on submissions
- Rubric scoring with criterion-level comments
- Annotation tools for written work
- Video/audio feedback (personal, nuanced)

### Step 9: Analyze Results and Adjust

#### 9.1 Analyze Item-Level Data
**Item Analysis**:
- **Difficulty**: % of students answering correctly
  - Too easy: >90% correct
  - Too hard: <40% correct
  - Ideal: 50-80% correct
- **Discrimination**: Do high performers answer correctly more than low performers?
- **Distractors**: Are incorrect options chosen? (If not, they're not functioning)

**Canvas Analytics**:
```python
canvas_get_student_summaries(course_id=12345)
# Review performance patterns
```

#### 9.2 Identify Learning Gaps
- Which objectives did students struggle with?
- Common errors or misconceptions?
- Unexpected patterns in performance?
- Need for re-teaching or additional practice?

#### 9.3 Refine Assessment
**Improvements Based on Data**:
- Revise poorly functioning items
- Adjust difficulty or clarity
- Add items for under-represented objectives
- Modify rubric criteria if needed

**Iterate**:
- Version control (Assessment v1, v2, v3)
- Document changes and rationale
- Share improvements with colleagues

### Step 10: Use Assessment to Improve Learning

#### 10.1 Provide Re-Learning Opportunities
- **Re-teaching**: For concepts most students missed
- **Targeted Practice**: Focus on common errors
- **Peer Tutoring**: High performers help struggling peers
- **Additional Resources**: Readings, videos, practice problems

#### 10.2 Offer Reassessment (when appropriate)
**Reassessment Policies**:
- Formative: Multiple attempts encouraged
- Summative: Conditional (after intervention)
- Maintain rigor: Different version, not easier
- Grade replacement or averaging (decide policy)

**Canvas Reassessment**:
```python
canvas_create_assignment(
    course_id=12345,
    name="Unit 3 Reassessment (Alternate Version)",
    description="For students who completed remediation",
    allowed_attempts=1,
    # Different items, same objectives and difficulty
)
```

#### 10.3 Reflect and Improve Instruction
**Reflection Questions**:
- Did my instruction prepare students adequately?
- Which teaching strategies were most/least effective?
- How can I adjust pacing, activities, or differentiation?
- What will I do differently in the next unit/course?

## Tools Needed

### Canvas MCP Tools
- `canvas_create_assignment` - Build assessments
- `canvas_create_quiz` - Objective item tests
- `canvas_create_quiz_question` - Add quiz items
- `canvas_create_rubric` - Scoring guides
- `canvas_get_submission` - Review student work
- `canvas_list_submissions` - Track completion
- `canvas_update_submission_grade` - Score and feedback
- `canvas_get_student_summaries` - Performance analytics

### Templates
- `templates/assessment-blueprint.xlsx` - Alignment tool
- `templates/item-analysis-sheet.xlsx` - Quality review
- `templates/feedback-template.md` - Consistent feedback

### Checklists
- `checklists/assessment-quality.md` - Validity/reliability
- `checklists/item-writing-best-practices.md` - Item quality
- `checklists/fair-assessment.md` - Equity and access

## Quality Checks

### Assessment Quality Criteria
1. **Validity**: Measures what it claims to measure?
2. **Reliability**: Produces consistent results?
3. **Fairness**: Equitable for all learners?
4. **Clarity**: Instructions and items unambiguous?
5. **Alignment**: Matches objectives in content and cognitive level?
6. **Comprehensiveness**: All objectives assessed?
7. **Practicality**: Feasible to administer and score?

### Pre-Administration Checklist
- [ ] Blueprint shows complete objective coverage
- [ ] All items aligned to objectives (content + cognitive level)
- [ ] Clear, unambiguous wording
- [ ] Rubrics prepared for constructed response
- [ ] Answer key accurate
- [ ] Instructions complete and clear
- [ ] Accommodations prepared
- [ ] Canvas assignment configured correctly
- [ ] Peer review completed

## Common Pitfalls

### ❌ Avoid These Mistakes

1. **Misalignment**
   - ❌ Objective requires analysis, assessment asks for recall
   - ✅ Match cognitive levels exactly

2. **Unclear Items**
   - ❌ "Which of the following is most important?" (subjective)
   - ✅ "According to the food web model, which organism is the primary producer?"

3. **Trivial Pursuit**
   - ❌ Testing obscure facts not in objectives
   - ✅ Assessing essential knowledge and skills

4. **All-or-Nothing**
   - ❌ One high-stakes test determines entire grade
   - ✅ Multiple assessments, formative and summative

5. **No Feedback Loop**
   - ❌ Score, record, move on
   - ✅ Analyze, re-teach, provide opportunities to improve

6. **Inaccessible**
   - ❌ Complex vocabulary, tiny font, no accommodations
   - ✅ Clear language, accessible format, UDL principles

7. **Scoring Inconsistency**
   - ❌ Vague rubric, subjective grading
   - ✅ Specific criteria, blind scoring, calibration

## Example Walkthrough

[See complete assessment example in `apply-backward-design.md` Stage 2]

## Related Tasks
- **Foundation**: `create-learning-objectives.md` - Align assessments
- **Scoring**: `create-rubric.md` - Build rubrics
- **Framework**: `apply-backward-design.md` - UbD Stage 2
- **Accessibility**: `apply-udl.md` - Multiple means of expression
- **Accessibility**: `accessibility-audit.md` - Ensure access
- **Implementation**: `canvas-course-build.md` - Build in Canvas

## References
- Stiggins, R.J., Arter, J., Chappuis, J., & Chappuis, S. (2004). *Classroom Assessment for Student Learning*
- McTighe, J., & Wiggins, G. (2013). *Essential Questions: Opening Doors to Student Understanding*
- Brookhart, S.M. (2013). *How to Create and Use Rubrics*
- Popham, W.J. (2017). *Classroom Assessment: What Teachers Need to Know* (8th ed.)
- Wiliam, D. (2011). *Embedded Formative Assessment*
- Black, P., & Wiliam, D. (1998). "Assessment and Classroom Learning"
